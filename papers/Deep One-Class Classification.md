# Deep One-Class Classification

元の論文の公開ページ : http://proceedings.mlr.press/v80/ruff18a/ruff18a.pdf

## どんなもの?
カーネルベースの一クラス分類と最小ボリューム推定からインスピレーションを受け、新しい深いAnomaly Deteciotn(以下AD)を提案する。その手法はDeep Support Vector Data Description(以下Deep SVDD)と名付ける。これはデータのネットワーク表現を包みこむ超球のボリュームを最小化するニューラルネットワークを学習する。下の図(論文中の図1)で言えば、
- 学習中にニューラルネットワーク(∅(・;W))を介して、入力空間(X)に含まれる入力には正常なデータ(黒点)のみが与えられ、出力先の出力空間(F)ではcを中心とする半径Rの超球が内部に点を含むように形成される。この時、ニューラルネットワークも学習する。
- 追加で、学習するデータがFにおいてcの付近にマッピングされるように、別の定義式を提案する。
- テスト時に異常なデータ(白点)が入力されても出力された時、その点は外側に位置するようになる(ニューラルネットワークによって、正常なデータに共通する要因を的確に抽出し出力しているため、異常なデータではその要因を正しく抽出できなくなり、結果として超球外に位置するようになる)。

![論文中の図1](img/DOC/fig_1.png)

## 先行研究と比べてどこがすごいの?
深層学習は革新的でありADでも深いADとして有望な結果を出しているが、ADベースの目的関数を最適化することによって学習されておらず、基本的に再構築誤差(入力と出力の誤差)に依存している。  
AutoEnocoder(以下AE)等の再構築誤差を使う学習を行うものは、学習時の入力に正常なデータだけを使い、その正常なデータに含まれる多様性の一般的要因を抽出できるようにする。また、再構築誤差を異常スコアとして使い異常検知も可能である。テスト時にこの要因を含む入力は入力に近似したものを出力できるが、そうではない入力は要因を抽出できなくなるので入力とは別のものが出力される。こうして再構築誤差を使ったものは異常検知ができる。

ただし、AEはADのために作られたものではない。そのため、AEをADに適応する際に入力情報をどこまで次元圧縮するか(以下compactness)の調節が必要となる。compactnessはハイパーパラメータであり、適切なバランスを取るのは難しい。

Deep SVDDはADの使用を前提としており、データを囲む超球のボリュームを最小限に抑えることで、適切なcompactnessを得ている。

なおAnoGANもAEと同様でどうやってcompactnessのためにジェネレータを正規化するかが問題になる。(????)

## 技術や手法のキモはどこ? or 提案手法の詳細
適切なcompactnessを得るための定義を以下に示す。
### 各定義
入力空間X⊆Rd、出力空間F⊆Rpとして、ニューラルネットワークを∅(・;W):X→F、隠れ層L∈Nで重みW=(W1,...,WL)、ここでWlはl∈{1,...,L}とする。また、∅(x,W)∈Fはx∈Xの特徴表現である。

### 仮定
Deep SVDDはWの調節とFを含む超球の最小化を同時に学習する。このとき、超級は半径R>0、中央c∈Fとする。

### soft-boundary Deep SVDD
学習データにDn={x1,...,xn}が与えられたとすると、soft-boundary(超球の境界線) Deep SVDDの目標は以下の定義式(論文中の式(3))となる。  
下の定義式によってデータ点が超球のcに密接にマッピングされるようなWをネットワークは学習できる。  

![論文中の式3](img/DOC/fig_0.png)

- 第一項はカーネルSVDDと同じようにR**2を最小にすることで超球を最小化することになる。
- 第二項は罰則項であり、ネットワークを通過したあと球の外にある点(つまり、中心からの距離が半径Rよりはるかに遠い点がある場合)のためである。ハイパーパラメーターv∈(0,1]は球のボリュームと限度違反のトレードオフを取り持つ。つまり、どれくらい球の外側の点を許容するか決められる。
- 最終項は重みを調節するための正則化を||・||Fのフロベニウスノルムとハイパーパラメーターλ>0で定義している。  

### One-Class Deep SVDD
学習データのほとんどが正常なデータである場合(一クラス分類など)、簡略化された損失を定義する。これは、∅(xi;W)とcの距離を罰則化するためのものである。定義式は以下のとおり。

![論文中の式4](img/DOC/fig_2.png)  

- 第一項はノルムによって示されている∅(xi;W)からcまでの距離を集計し、平均に直したもの。
- 第二項は正則化を行うためのものであり、ハイパーパラメーターλ>0を含む。

soft-boundary Deep SVDDは直接半径にペナルティを課して縮小するのに対し、One-Class Deep SVDDはFでのデータ表現を中心(cの近く)まで抑えることができる。

### anomaly score
異常値であるかどうかを表す指標。定義式は以下の通り。この値からR*を引いたものが負であれば正常なデータ(超球内)であり、正であれば異常なデータ(超球外)である。  

![論文中の式5](img/DOC/fig_5.png)

## どうやって有効だと検証した?
MNISTとCIFAR-10を使った異常検知タスクと、Boundary AttackをGTSRB stop datasetに適応したAdversarial attacksの評価を行った。下図のKDEはKernel density estimation、IFはIsolation Forestである。

![論文中の表1](img/DOC/fig_3.png)

![論文中の表2](img/DOC/fig_4.png)

## 議論はある?
考えつかない

## 次に読むべき論文は?
- Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery (もう読んだけど再度確認)  

## 論文関連リンク
- 本家:http://proceedings.mlr.press/v80/ruff18a.html
- 本家実装:https://github.com/lukasruff/Deep-SVDD

## 参考リンク
- なし

## 会議
ICML2018

## 著者/所属機関
Lukas Ruff, Robert A. Vandermeulen, Nico G ̈ornitz, Lucas Deecke, Shoaib A. Siddiqui, Alexander Binder, Emmanuel M ̈uller, Marius Kloft

## 投稿日付(yyyy/MM/dd)
2018/??/??

## コメント
提案手法がシンプル。論文1章にあるように一クラス分類(異常検知)が他の分類タスクと比べてそこまで活発ではないせいか(いつしかの国際会議のワークショップでも、生成モデルは満員だったのに一クラス分類は空席が目立っていたことがあった)。特性についてももうちょっと理解を深めたい。

## key-words
2D_Image, One-Class_&_Anomaly_Detection

## status
更新済