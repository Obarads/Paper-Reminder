# You Only Look Once: Unified, Real-Time Object Detection

a URL for the published paper : [arxiv.org](https://arxiv.org/abs/1506.02640)  
Github Issues : []()  

Note: most contents of this file is quoted from the paper. Direct quotations are indicated by double quotation, indirect quotation by unadornment, and my memos by brackets.  
**Caution : This contents cannot guarantee original meaning of the paper (rewording in indirect quotation, my memos, etc.). Please point out my errors to me if you identify ones.**

## What's this paper?
This paper proposed YOLO, new object detection model for RGB image.
- This "unified architecture is extremely fast."
    - "Base YOLO model processes images in real-time at 45" FPS (frames per second).
    -  Fast YOLO (A smaller version of the network) processes an 155 FPS.
        - Fast YOLO achieved "double the mAP of other real-time detectors" [as of 2015].
    - "Compared to SOTA detection systems, YOLO makes more localization errors but is less likely to predict false positives on background."
    - "YOLO learns very general representations of objects."

## What's amazing in comparison with existing studies? or Related works


## What's the key of method? or The method detatil

## How to experiment

## Is there a discussion?

## Which paper should I read next?
- None

## Things related my article
1. None

## Conference, Journal, etc.
CVPR 2016

## The author
Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi

## Release date(yyyy/MM/dd)
2015/07/08

## My comments
None

## key-words
CV, English, RGB_Image, Detection, Supervised_Learning

## status
未完

## read

## Citation
