# Unsupervised Representation Learning by Predicting Image Rotations

## どんなもの?
入力として得られる画像に適応された2Dの回転を認識するようにConvNetsを訓練させて画像特徴を学習するself-supervised学習を行うRotNetを提案した。実装自体はあまりにも簡単であるため、結果への考察が主となる。

## 先行研究と比べてどこがすごいの?
既存のself-supervised学習の研究は教師あり学習の精度になかなか追いつけないものが多かった。しかし、今回提案するRotNetはシンプルな考え方でありながら、既存のそれらの学習方法を大幅に上回り、教師あり学習との結果を肉薄にするものとなった。

## 技術や手法のキモはどこ?
幾何学変換の集合としてこれらの画像の回転をを使う背景にある中心的な直観は簡単な事実に関連するものである。その事実とは、ConvNetモデルが、画像内で意味的な部分などの物体のクラスを検出又は認識することを最初に学ばない限り、上記の回転認識タスクを効果的に実行することは本質的に不可能であるということである。つまり、画像の回転の予測に成功するために、ConcNetは画像中の目立つ部分を見つけ出すことを必ず学ばなければならず、物体のタイプと姿勢を検知し、そして物体の姿勢をそれぞれの物体のタイプが利用する画像の中で描写される傾向があるdominant orientation(?)と関連付ける。

## どうやって有効だと検証した? 

### CIFAR-10による評価
最初にCIFAR-10の物体認識タスク上で、提案された回転認識のself-supervisedタスクによる特徴学習を基とするConvNetを評価する。ここで、回転認識のself-supervisedタスクで訓練されたConvNetモデルをRotNetと呼ぶ。

- **学習された階層の評価**  
    はじめに、学習した特徴の品質が深さ(層の深さ)やRetNetモデル全体の深さからどのように依存しているか調査する。

    1. まずは、畳み込みブロックが3、4、5個ある3つのRotNetモデル(基となるNetwork-In-Network(以下NIN)アーキテクチャでは1つの畳み込みブロックに3つの畳み込み層があるため、層は9、12、15個となる)にCIFAR-10を使ったトレーニングを行う。  
    1. 次に、それぞれの畳み込みブロックによって生成された特徴マップの上部で分類器を学習する(要はFine-tuning?)。これらの分類器にはCIFAR-10の教師あり訓練手法を使う。分類器は3つのFC層からなり、2つの隠れ層には200の特徴チャンネルがあり、バッチノルム、Reluユニットと続く。

    結果は以下のようになった。

    ![tab1](img/URLbPIR/fig_0.png)

    2番目以降のブロックは精度が下がっているが、これは層が進むごとに回転予測のself-supervisedタスクでどんどん明細になるからである。(???) また、RotNetの総深度が増えると前の層(と1番目のconvブロックの後)によって生成された特徴マップにより、物体検知パフォーマンスが向上することを観測できた。これは、モデルの深さを増やすことで頭部の複雑さ(上部のConvNet層)は前の層の特徴を回転予測タスクにあまり特化しない様にさせる。(?)

- **角度の選定**  
    もっとも精度が良いのは4つのパターンのときである。物体検出には2つのクラスだけでは少なすぎ、逆に8つの場合は十分に区別できない上に135°など奇数の角度の際に現れる副作用(おそらく線の曖昧さの増幅)によって効果が下がると考えられる。また、0と180度の組と90と270度の組では後者のほうが低いが、これは単に制度を測る際の方向(0度)に沿った学習がうまくできていないため。結果は以下の通り。

    ![tab2](img/URLbPIR/fig_1.png)

- **教師ありと他の教師無しとRotNetの比較**  
    ここでは、合計で4つのconvブロックを持つRotNetモデルの二番目のConvブロックで生成された特徴マップを使う。これらのRotNetで2つの異なる分類器を使い訓練する。

    - 従来通りの非線形分類器に3つのFC層を使う(RotNet + non-linear)。
    - 3つのconv層と線形予測層(RotNet + conv)

    尚、分類器より前の構造は3つのNINモデルのブロックからなる。最初の2つはRotNetのモデルを使うが、3つ目はランダムな初期化がされる。  
    以上の設定を用いた結果は以下のようになる。

    ![tab3](img/URLbPIR/fig_2.png)

## 議論はある?

## 次に読むべき論文は?
-
-

### 論文関連リンク
1. 本論文:https://arxiv.org/abs/1803.07728
2. 

### 参考リンク
-
-

### 会議
ICLR 2018

### 著者/所属機関

### 投稿日付(yyyy/MM/dd)
2018/12/15

## コメント
